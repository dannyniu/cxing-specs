2025-11-20 Proposed Amendment to Enhance Comparision
====

As identified in https://github.com/dannyniu/cxing-specs/issues/2 there had
been wording problems with current definition of comparisions. Further
investigation shows that current comparision doesn't fullfill the end-goal of
having surprise-free semantic laid out in the introduction of the langauge spec.

For example, comparision of 2 strings in most dynamic language are actual
string comparsions, whereas in CXING, it's object identity comparision. While
it was believed at first this wouldn't be too big a problem, the question was
raised, as to whether it's benefitial in the first place to make most strings
compare unequal. On the security ground, having a loose comparision that allow
too much equality to hold true has proven to be a real-world vulnerability, it
would probably be more costly to have more verbose code for comparision.

Yet, the runtime semantic of the language enabled from the start, for numerical
and stringwise comparision to safely coexist, had the comparision operators been
more carefully designed, as such we're so revising them.

The Description of the Proposal
====

For strings, and in fact any object possessing this method, the `cmpwith()`
method and the `equals()` method will be used to 'order' and 'identify' objects,
and comparision operators on encountering these objects, will resort to these
method functions. For arithmetic context, the comparision remains the same.

This brings to the second problem, a suprise-free definition of relevant
semantics. For starters:

> - Function are identity compared,
> - Objects are first examined for the comparison methods,
>   - if found in both operands, they're interrorgated for compatibility,
>     that is, if they're the same method function, then the remaining
>     comparision may proceed.
>   - if the corresponding methods are not the same function, or one is missing,
>     then this brings to **Q1**: how should this part be defined to maintain
>     the symmetry and tansitive property of the comparision?
>   - if both methods are same and thus compatible, one of these object is used
>     as the `this` object, and the method is called with it, and the other
>     operand, and the return value is the result of the comparision.
> - If either operand is not an object, then they're compared under arithmetic
>   context according to existing rules.

The **Q1** is a tricky one. Some object may have "subclasses", in many people's
opinion, an object in its subclass should compare equal to itself in the super
class. And this is easy, just overload the comparision to recognize the super
class, but what about the converse - i.e. `SuperClassObj.equals(SubClassObj)`,
because we definitely don't want `SubClassObj === SuperClassObj` to be unequal
to `SuperClassObj === SubClassObj`.

**Side Note**: Or perhaps that can be a way to identify the class hierarchy
between objects, but that's a later story.

Secondly, there can be 3 objects `a`, `b`, `c`, such that `a === b` and `b === c`
holds, yet `a === c` doesn't. This is undesirable.

Preserving Symmetry and Transitivity of Equality Relation
----

To pick up where **Q1** left off:

> - For the loose comparision operator `==`:
>   - if the `equals()` method of at least 1 operand returns true when evaluated,
>     then the both operand compares equal,
>   - otherwise, if the value proper of the value native object of both operands
>     compares equal, then both operands are considered compare equal,
>   - otherwise, the two operands compares unequal.
> - For the strict comparison operator `===`:
>   - The expression `a === b`, is true if and only if
>     the expression `a.equals(b) || b.equals(a)` evaluates to true.

Now examine the properties of this definition.

- For loose comparision operator `==`:
  - The symmetry property among 'subclass' and 'super class' would be preserved
    as long as one of them has an `equals()` method that recognizes the other.
    This is *Desirable*.
  - The transitivity property between 'descendent class' and 'anscestor class'
    can be preserved IF they are the same object in the sense that
    the 'value proper' compares equal pointer-wise for the object.
    This is *Desirable*.
  - The case with `(a==b) == true` and `(c==b) == true` but `(a==c) == false`
    is *Undesirable* but would still exist. And under the new definition,
    would imply that:
    1. `a` and `c` don't share the same underlying pointer and don't have
       compatible `equals()` method.
    2. the set of method properties (including `equals()`) on the two objects
       represents two sets of non-interchangable externally obersable behaviors.

Eventhough identified as undesirable, that last case have however one
_desirable_ usecase. For example, the identity elements of complex numbers,
and quaternions, would both compare equal to the identity elements of real
numbers. But the complex identities and quaternion identities probably
shouldn't compare equal to each other.

This preserves the symmetry property of the equality relation. It doesn't
preserve the transitive property in all cases, but for the good reason that
objects of different type shouldn't compare equal even if they're equal to
some other 'reference'.

- For strict comparision operator `===`:
  - The symmetry property is preserved. This is *Desirable*.
  - The transitive property is not preserved, but for the very same reason
    as that for the loose comparison operator `==`.

A plus of this definition, is that it allows for the idiom
of `a == b && a !== b` to identify compatible objects of different underlying
pointer. (The expression `a !== b` will be informally defined as `!(a === b)`
for the purpose of this section.)

If one were to find out the 'class hierarchy' should they employ such concept in
the program code, they can call the `equals()` method explicitly to de-symmetricize.

Preserving the Well-Formedness of Ordering
----

So far, we've only discussed equality part of the comparison, and haven't
touched on inequality comparison yet. Straightforwardly, we have the following:

> - For the relation comparision operators `<`, `<=`, `>`, and `>=` the
>   comparison function `cmpwith()` is called with the left operand as
>   the `this` parameter, and the right operand as the only argument.
>   The operators results in true if and only if the method function
>   returns -1, one of -1 and 0, 1, and one of 1 and 0 respectively,
>   and false otherwise.

That allows for strings to collate expressively using relation operators.
However, there's a problem. The current rules are:

> Under a integer context:
> - the special value `null` have value 0,
> - all opaque objects have a single value of 1,
> - floating point values are converted by discarding fractional part, with the
>   behavior on overflow being UNSPECIFIED.
>
> Under the floating point context:
> - integers are converted preserving value to the extent allowed by precision.
> - the special value `null` is converted to `NaN`.
> - all opaque objects are converted to `+1.0`.
>
> Under arithmetic context:
> - before the following occur, opaque objects are converted to 1 in `long`.
> - operations involving only `long`s results in `long` operands;
> - operations involving `ulong` but not `double` results in `ulong` operands;
> - operations involving `double` results in `double`;
> - operations involving `null` are treated specially - if there are `double`,
>   the `null` is converted to `NaN`, otherwise, to 0 under integer context.

and we'd have: `(null <= 0) && !(null <= 0.0)` due to the way nulls are being
converted. What we want, is for null to be 'unordered' while being numerically
zero. Additionally, there's the discrepancy with `!(null+0 == null+0.0)`, which
since noticed, might as well be eliminated altogether in this instance.

It had been shown that, whether null converts to NaN or 0 depends on whether
the operation produces boolean result from arithmetic operands. This observation
is important: there are
1. arithmetic operations producing arithmetic results from arithmetic operands,
2. logic predicates producing boolean results from arithmetic operands, and
3. logic operations producing boolean results from boolean logic operands.

For 3, all operands and results are in integer context, no problem.
As to why null is zero in 1 and unordered in 2 - while like NaN, null is also
regarded as erroneous value, it can also be found in uninitialized variables or
object member properties. Because of the fact that
- it can be the initial state of a variable, it needed a sane default value,
- it is uninitialized, it shouldn't 'weigh' in ordering.

Whereas NaN on the other hand, is the end result of a erroneous computation,
and so it's not the initial state of a variable, thus it doesn't have a default
to begin with (other than what would be offered in any potential null-coalescing
operations).

Hence the revised text for integer, floating point, and arithmetic contexts:

> The "implicit type and value conversion" apply to multiple operands in such way
> that there's one common type (or special value) that is the same regardless of
> the order of the operands. This conversion is defined in terms of a binary
> operation that is associative and commutative, so that any binary expression
> operator that is associative and commutative preserve this property
> regardless of the type of the operands.
>
> Under a integer context:
> - all opaque objects have a single value of 1,
> - floating point real numbers are converted by discarding fractional part,
> - the conversion of infinities and NaN are UNSPECIFIED.
>
> Under the floating point context:
> - integers are converted preserving value to the extent allowed by precision.
> - all opaque objects are converted to `+1.0`.
>
> Under arithmetic context:
> - before the following occur, opaque objects are converted to 1 in `long`.
> - operations involving only `long`s results in `long` operands;
> - operations involving `ulong` but not `double` results in `ulong` operands;
> - operations involving `double` results in `double`;
>
> The special value `null` is treated specially:
> - for operators that evaluates the order between operands, operands are
>   converted to `null`, which is neither less nor greater than any integer or
>   floating point number - this is known as the *order evaluation conversion*.
> - for operators that computes a value from operands, the `null` is converted
>   to the integer `0`, or if there're `double`, to `+0.0` -
>   this is known as the *value computation conversion*
>
> Operators shall document whether they evaluate the order of, or compute a
> value from operands. In general, operators that returns true/false predicate
> from arithmetic operands evaluates the order, while ones that computes a value
> would evaluate to arithmetic types.

The Proposed Amendment to Specification Text
====

_See later spec text pushed in a later commit._

Afterwords
====

While overloading operator with methods was first used to solve the most pressing
issue of semantic surprise with comparison operators, we do not regard it as
an opportunity to extend it to a general operator overloading mechanism. Instead,
the careful evaluation of preservation of symmetry and transitive property of
equality comparision has been a study case of eliminating unnecessary surprise
in corners of languages that're unexpected to exist - both in the spec of the
language, and in actual code.

Another insightful study case, had been to find a rationale to distinguish the
arithmetic valuedness and relational unorderedness of null. While NaN had
conventionally been valueless and unordered from the start, the existing
conversion rules proved insufficient when dealing with idioms such as incrementing
an uninitialized null variable to one as if it had the value of zero. We found
that, although null and NaN had many similarities, one is the _start_ of
computation, while the other is the _end_ result of computation errors.
